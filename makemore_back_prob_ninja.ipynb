{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba3f4d3-8620-4b45-8048-c3736ae6e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb197ce6-d904-4448-9bf9-42c8d102d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "if Path('names.txt').exists():\n",
    "    words = open('names.txt', 'r').read().splitlines()\n",
    "else:\n",
    "    req = requests.get(r'https://raw.githubusercontent.com/karpathy/makemore/master/names.txt')\n",
    "    with open('names.txt', 'wb') as f:\n",
    "        f.write()\n",
    "    words = open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59323a6c-429b-4031-a70f-44df451bcc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a973c3c-b120-4028-bd6f-be1458754e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf2feccd-1a49-43bc-8b03-b868c5548c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e750c59-b11b-4858-aafc-77d78b30f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function which we will use later when copamring Manual Gradients to Pytorch Gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f\"{s:15s} | exact: {str(ex):5s} | approximate {str(app):5s} | maxdiff: {maxdiff}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af444748-b7a3-4b9f-996f-9a5f6133ee27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Themes: \n",
      "   chesterish\n",
      "   grade3\n",
      "   gruvboxd\n",
      "   gruvboxl\n",
      "   monokai\n",
      "   oceans16\n",
      "   onedork\n",
      "   solarizedd\n",
      "   solarizedl\n"
     ]
    }
   ],
   "source": [
    "!jt -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad472e38-0e1d-4fd9-bb5d-330411fbf19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='onedork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b1fea37-5021-4dee-9d40-6990fa36f0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 64\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "C = torch.randn((vocab_size, n_embd), generator = g)\n",
    "\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator= g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator = g) * 0.1  # using b1 just for fun, it's useless because of BN\n",
    "\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator = g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator = g) * 0.1\n",
    "\n",
    "#BatchNorm Parameters\n",
    "bngain = torch.randn((1, n_hidden), generator = g)*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden), generator = g) * 0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "733b5ec5-723d-4e32-b94c-257488925e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size #a shorter variable for convinence\n",
    "#constrcut a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0],(batch_size,), generator = g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a96e3615-cec5-4a73-9193-e2a4264f4952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2428, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Forward pass,k \"chunckated into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into the vector\n",
    "embcat = emb.view(emb.shape[0], -1) #Concatenate the vectors\n",
    "\n",
    "#liner layer 1 \n",
    "hprebn = embcat @ W1 + b1 #hidden layer pre activation\n",
    "#Batch Norm Layer\n",
    "bnmeani= 1/n*hprebn.sum(0,keepdim = True) #(hprebn.sum(0,keepdim = True)/n)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff **2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim= True) #note : Bessel's Correction (dividing by n-1 , not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**0.5\n",
    "bnraw = bndiff - bnvar_inv\n",
    "hpreact = bngain * bnraw +bnbias\n",
    "\n",
    "#Non Linearity\n",
    "h = torch.tanh(hpreact) #hidden layer\n",
    "\n",
    "#linear layer 2\n",
    "logits = h @ W2 + b2 #Output Layer\n",
    "\n",
    "#cross entropy loss (same as F.cross_Entropy loss)\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes #subtract the max for numerical stability refer the previous notebooks \n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims = True)\n",
    "counts_sum_inv = counts_sum ** -1  # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "#pytorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06805db2-3af2-4e9b-9ea9-209606f6cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea54ba48-79b7-4a00-8fb6-70f55f3560e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs shape torch.Size([32, 27])\n",
      "Calculating the gradients for ech parameters or steps which will be used in back propagation\n",
      "\n",
      "the gradients that need to be updated for a step are calculated by finding the derivative from the succeeding step and\n",
      "will be stored in the parameter.grad \n",
      " \n",
      "since the most part of the logprobs which has the shape of torch.Size([32, 27]) is gonna be zero     \n",
      "Because only the logprobs[range(n), Yb] of shape torch.Size([32]) will be taken into consideration\n",
      "      and loss of other logits or logprobs will be derviatively - d/dx zero\n",
      "\n",
      "-----Implementing the derivative-----\n",
      "logprobs        | exact: True  | approximate True  | maxdiff: 0.0\n",
      "\n",
      "\n",
      "derivative of probs.log() is equivalent to log(x) which is 1/x and need to implement chain rule      \n",
      "that is wee need to find the derivative of probs which is dlogprobs\n",
      "Compare the gradients probs.grad[range(n), Yb] and dprobs[range(n), Yb]\n",
      "(1.0/probs) * dlogprobs  this will boost the gradient if the predicted logits / probs of the actual value is low and\n",
      "will remain the same if the prob is One\n",
      "probs           | exact: True  | approximate True  | maxdiff: 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cmp('logprobs', dlogprobs, logprobs)\n",
    "print('logprobs shape',logprobs.shape)\n",
    "#calcualte the dlogprobs \n",
    "#example loss = -(a + b + c) /3 where 3 is the n \n",
    "#dloss/da = -1/3 where b and c are constatnts and will become zero so the derivative loss for n logits can be written as -1/n\n",
    "print(f\"Calculating the gradients for ech parameters or steps which will be used in back propagation\\n\")\n",
    "print(\"the gradients that need to be updated for a step are calculated by finding the derivative from the succeeding step and\\\n",
    "\\nwill be stored in the parameter.grad \\n \")\n",
    "print(f\"since the most part of the logprobs which has the shape of {logprobs.shape} is gonna be zero\\\n",
    "     \\nBecause only the logprobs[range(n), Yb] of shape {logprobs[range(n), Yb].shape} will be taken into consideration\\n \\\n",
    "     and loss of other logits or logprobs will be derviatively - d/dx zero\")\n",
    "\n",
    "print(\"\\n-----Implementing the derivative-----\")\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "#1.0/n is the equivalent of dloss/dlogprobs\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "print(\"\\n\")\n",
    "\n",
    "# cmp('probs', dprobs, probs)\n",
    "# now find the gradient of probs which will the derivative from the logprob step\n",
    "print(f\"derivative of probs.log() is equivalent to log(x) which is 1/x and need to implement chain rule\\\n",
    "      \\nthat is wee need to find the derivative of probs which is dlogprobs\")\n",
    "print(\"Compare the gradients probs.grad[range(n), Yb] and dprobs[range(n), Yb]\")\n",
    "dprobs = (1.0/probs) * dlogprobs \n",
    "##take the derivative of the log(probs) and multiply it with the corresponding function's output i.e chain rule\n",
    "print('(1.0/probs) * dlogprobs  this will boost the gradient if the predicted logits / probs of the actual value is low and\\\n",
    "\\nwill remain the same if the prob is One')\n",
    "cmp('probs',dprobs,probs)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "## cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5b30694-5f35-48fa-b6e0-0ac54b42ee2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9454, -0.6465, -0.4427, -1.3778, -2.1524, -1.3471, -0.7747, -0.9195,\n",
       "        -0.9838, -0.3466, -0.8451, -2.5647, -2.0578, -0.4210, -0.5281, -0.1968,\n",
       "        -0.6192, -0.5962, -0.5374, -0.7043, -0.4710, -2.7058, -0.8241, -0.7326,\n",
       "        -0.8043, -0.9942, -0.4093, -0.7209, -2.0475, -0.7810, -0.2489, -0.7494])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.grad[range(n), Yb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28202500-bbcd-4e93-988f-da5e8985f7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9454, -0.6465, -0.4427, -1.3778, -2.1524, -1.3471, -0.7747, -0.9195,\n",
       "        -0.9838, -0.3466, -0.8451, -2.5647, -2.0578, -0.4210, -0.5281, -0.1968,\n",
       "        -0.6192, -0.5962, -0.5374, -0.7043, -0.4710, -2.7058, -0.8241, -0.7326,\n",
       "        -0.8043, -0.9942, -0.4093, -0.7209, -2.0475, -0.7810, -0.2489, -0.7494],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dprobs[range(n), Yb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b7bb739-7667-44c6-8685-707ffb14ec8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3005],\n",
       "        [-0.3150],\n",
       "        [-0.2796],\n",
       "        [-0.2337],\n",
       "        [-0.4312],\n",
       "        [-0.1302],\n",
       "        [-0.3757],\n",
       "        [-0.2686],\n",
       "        [-0.2426],\n",
       "        [-0.2386],\n",
       "        [-0.3327],\n",
       "        [-0.3124],\n",
       "        [-0.2907],\n",
       "        [-0.2194],\n",
       "        [-0.2967],\n",
       "        [-0.1968],\n",
       "        [-0.2963],\n",
       "        [-0.2662],\n",
       "        [-0.3225],\n",
       "        [-0.1968],\n",
       "        [-0.2341],\n",
       "        [-0.1968],\n",
       "        [-0.1968],\n",
       "        [-0.3441],\n",
       "        [-0.1968],\n",
       "        [-0.2524],\n",
       "        [-0.3274],\n",
       "        [-0.2142],\n",
       "        [-0.1968],\n",
       "        [-0.2637],\n",
       "        [-0.2489],\n",
       "        [-0.2985]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_sum_inv.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2283206c-e87b-45d1-8e48-5e26b00c645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27]) torch.Size([32, 1])\n",
      "the shape is not matched so it will braod cast the tensors/ logits that is the 32 columns will be broadcasted 27 times \n",
      "If we want to take the derivative of 2 fns we have to take them with respect to each other\n",
      "dcount_sum_inv shape is torch.Size([32, 1])\n",
      "counts_sum_inv  | exact: True  | approximate True  | maxdiff: 0.0\n",
      "\n",
      "we are not checking the gradienst yet because the we calculated only the first contribution of counts\n",
      "`probs = counts * counts_sum_inv` we have another contribution from the counts `counts_sum = counts.sum(1, keepdims=True)`\n",
      "dcounts_sum.shape = torch.Size([32, 1])\n",
      "counts_sum      | exact: True  | approximate True  | maxdiff: 0.0\n",
      "counts.shape torch.Size([32, 27]), counts_sum.shape torch.Size([32, 1])\n",
      "counts          | exact: True  | approximate True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "## cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "# counts_sum_inv is 1/counts_sum\n",
    "print(counts.shape, counts_sum_inv.shape)\n",
    "print(\"the shape is not matched so it will braod cast the tensors/ logits that is the 32 columns will be broadcasted 27 times \")\n",
    "\n",
    "# c = a * b\n",
    "# a[3 x 3] * b[3x1]\n",
    "# a11*b1 a12*b1 a13*b1\n",
    "# a21*b2 a22*b2 a23*b2\n",
    "# a31*b3 a32*b3 a33*b3\n",
    "\n",
    "print(\"If we want to take the derivative of 2 fns we have to take them with respect to each other\")\n",
    "# da*b/da = b    ,  da*b/db = a  and multiple the chain rule of that particular function\n",
    "#counts * dprobs will be of shape 32 * 27 but we nned 32 * 1 \n",
    "# because thats the shape of counts_sum_inv and we are doing it by adding all the gradients across the rows\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims = True)\n",
    "print(f\"dcount_sum_inv shape is {dcounts_sum_inv.shape}\")\n",
    "\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "\n",
    "# cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "#Now we have to derivate with respect to counts now\n",
    "\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "\n",
    "print(\"\\nwe are not checking the gradienst yet because the we calculated only the first contribution of counts\\n\\\n",
    "`probs = counts * counts_sum_inv` we have another contribution from the counts `counts_sum = counts.sum(1, keepdims=True)`\")\n",
    "\n",
    "# derivatives of counts_sum**-1 can be writen as d(1/x)/dx = -1/x**2\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "print(f'dcounts_sum.shape = {dcounts_sum.shape}')\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "\n",
    "#derivatives of counts.sum(1, keepdims=True)\n",
    "print(f\"counts.shape {counts.shape}, counts_sum.shape {counts_sum.shape}\")\n",
    "\n",
    "#a11 a12 a13 ----> b1 (= a11 + a12 + a13)\n",
    "#a21 a22 a23 ----> b2 (= a21 + a22 + a23)\n",
    "#a31 a32 a33 ----> b1 (= a31 + a32 + a33)\n",
    "#the derivatives of b1 sould be distributed equally across its respective inputs that is a11 a12 a13 .... applied similarly to all\n",
    "# we have to create a 32 x 27 from 32 x 1\n",
    "#we have to add the dcounts to the first branch also\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "# dcounts -> output\n",
    "# tensor([[17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747,\n",
    "#          17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747,\n",
    "#          17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747,\n",
    "#          17.9747, 17.9747, 17.9747],\n",
    "#         ...................\n",
    "# after adding the branchs of counts\n",
    "# tensor([[17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747,\n",
    "#          17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747,\n",
    "#          17.9747, 17.9747, 17.9747, 17.9747, 17.8570, 17.9747, 17.9747, 17.9747,\n",
    "#          17.9747, 17.9747, 17.9747],\n",
    "#         ...........\n",
    "# dcounts\n",
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb80b170-7a56-47c3-8aba-cdcabe183050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate True  | maxdiff: 0.0\n",
      "shape of dnorm_logits torch.Size([32, 27]) | shape of logits torch.Size([32, 27])| shape of logit_maxes torch.Size([32, 1])\n",
      "logit_maxes     | exact: True  | approximate True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "# local derivative of e**x is e**x\n",
    "\n",
    "dnorm_logits = counts * dcounts  #applied chain rule\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "\n",
    "# cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "#norm_logits = logits - logit_maxes\n",
    "print(f\"shape of dnorm_logits {dnorm_logits.shape} | shape of logits {logits.shape}\\\n",
    "| shape of logit_maxes {logit_maxes.shape}\")\n",
    "\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim =True)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "dlogits.shape\n",
    "\n",
    "# cmp('logits', dlogits, logits)\n",
    "# logit_maxes  = logits.max(1, keepdim=True).values\n",
    "\n",
    "dlogits += F.one_hot(logits.max(1).indices , num_classes = logits.shape[1]) * dlogit_maxes\n",
    "dlogits\n",
    "cmp('logits', dlogits, logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a23f58b-c3b9-4e88-82b8-e47d8a10b290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33d95be0-dcf3-4a09-b3b3-4889d3cf47ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x226df649550>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices , num_classes = logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3e41e-9a47-4f59-888c-8ec8421c95d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
