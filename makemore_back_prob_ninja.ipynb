{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba3f4d3-8620-4b45-8048-c3736ae6e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb197ce6-d904-4448-9bf9-42c8d102d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "if Path('names.txt').exists():\n",
    "    words = open('names.txt', 'r').read().splitlines()\n",
    "else:\n",
    "    req = requests.get(r'https://raw.githubusercontent.com/karpathy/makemore/master/names.txt')\n",
    "    with open('names.txt', 'wb') as f:\n",
    "        f.write(req.content)\n",
    "    words = open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59323a6c-429b-4031-a70f-44df451bcc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a973c3c-b120-4028-bd6f-be1458754e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf2feccd-1a49-43bc-8b03-b868c5548c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182541, 3]) torch.Size([182541])\n",
      "torch.Size([22780, 3]) torch.Size([22780])\n",
      "torch.Size([22825, 3]) torch.Size([22825])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(2147483647)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e750c59-b11b-4858-aafc-77d78b30f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function which we will use later when copamring Manual Gradients to Pytorch Gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f\"{s:15s} | exact: {str(ex):5s} | approximate {str(app):5s} | maxdiff: {maxdiff}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b1fea37-5021-4dee-9d40-6990fa36f0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 64\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embd), generator = g)\n",
    "\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator= g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator = g) * 0.1  # using b1 just for fun, it's useless because of BN\n",
    "\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator = g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator = g) * 0.1\n",
    "\n",
    "#BatchNorm Parameters\n",
    "bngain = torch.randn((1, n_hidden), generator = g)*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden), generator = g) * 0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "733b5ec5-723d-4e32-b94c-257488925e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size #a shorter variable for convinence\n",
    "#constrcut a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0],(batch_size,), generator = g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a96e3615-cec5-4a73-9193-e2a4264f4952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4513, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Forward pass,k \"chunckated into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into the vector\n",
    "embcat = emb.view(emb.shape[0], -1) #Concatenate the vectors\n",
    "\n",
    "#liner layer 1 \n",
    "hprebn = embcat @ W1 + b1 #hidden layer pre activation\n",
    "#Batch Norm Layer\n",
    "bnmeani= 1/n*hprebn.sum(0,keepdim = True) #(hprebn.sum(0,keepdim = True)/n)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff **2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim= True) #note : Bessel's Correction (dividing by n-1 , not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw +bnbias\n",
    "\n",
    "#Non Linearity\n",
    "h = torch.tanh(hpreact) #hidden layer\n",
    "\n",
    "#linear layer 2\n",
    "logits = h @ W2 + b2 #Output Layer\n",
    "\n",
    "#cross entropy loss (same as F.cross_Entropy loss)\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes #subtract the max for numerical stability refer the previous notebooks \n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims = True)\n",
    "counts_sum_inv = counts_sum ** -1  # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "#pytorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24ad3381-dc2b-4175-a17e-bbffeb44ef2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate True  | maxdiff: 0.0\n",
      "bndiff          | exact: False | approximate False | maxdiff: 0.000994503148831427\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "\n",
    "# print(h)\n",
    "    \n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "# cmp('bnvar', dbnvar, bnvar)\n",
    "# cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "# cmp('bnmeani', dbnmeani, bnmeani)\n",
    "# cmp('hprebn', dhprebn, hprebn)\n",
    "# cmp('embcat', dembcat, embcat)\n",
    "# cmp('W1', dW1, W1)\n",
    "# cmp('b1', db1, b1)\n",
    "# cmp('emb', demb, emb)\n",
    "# cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06805db2-3af2-4e9b-9ea9-209606f6cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea54ba48-79b7-4a00-8fb6-70f55f3560e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs shape torch.Size([32, 27])\n",
      "Calculating the gradients for ech parameters or steps which will be used in back propagation\n",
      "\n",
      "the gradients that need to be updated for a step are calculated by finding the derivative from the succeeding step and\n",
      "will be stored in the parameter.grad \n",
      " \n",
      "since the most part of the logprobs which has the shape of torch.Size([32, 27]) is gonna be zero     \n",
      "Because only the logprobs[range(n), Yb] of shape torch.Size([32]) will be taken into consideration\n",
      "      and loss of other logits or logprobs will be derviatively - d/dx zero\n",
      "\n",
      "-----Implementing the derivative-----\n",
      "logprobs        | exact: True  | approximate True  | maxdiff: 0.0\n",
      "\n",
      "\n",
      "derivative of probs.log() is equivalent to log(x) which is 1/x and need to implement chain rule      \n",
      "that is wee need to find the derivative of probs which is dlogprobs\n",
      "Compare the gradients probs.grad[range(n), Yb] and dprobs[range(n), Yb]\n",
      "(1.0/probs) * dlogprobs  this will boost the gradient if the predicted logits / probs of the actual value is low and\n",
      "will remain the same if the prob is One\n",
      "probs           | exact: True  | approximate True  | maxdiff: 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cmp('logprobs', dlogprobs, logprobs)\n",
    "print('logprobs shape',logprobs.shape)\n",
    "#calcualte the dlogprobs \n",
    "#example loss = -(a + b + c) /3 where 3 is the n \n",
    "#dloss/da = -1/3 where b and c are constatnts and will become zero so the derivative loss for n logits can be written as -1/n\n",
    "print(f\"Calculating the gradients for ech parameters or steps which will be used in back propagation\\n\")\n",
    "print(\"the gradients that need to be updated for a step are calculated by finding the derivative from the succeeding step and\\\n",
    "\\nwill be stored in the parameter.grad \\n \")\n",
    "print(f\"since the most part of the logprobs which has the shape of {logprobs.shape} is gonna be zero\\\n",
    "     \\nBecause only the logprobs[range(n), Yb] of shape {logprobs[range(n), Yb].shape} will be taken into consideration\\n \\\n",
    "     and loss of other logits or logprobs will be derviatively - d/dx zero\")\n",
    "\n",
    "print(\"\\n-----Implementing the derivative-----\")\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "#1.0/n is the equivalent of dloss/dlogprobs\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "print(\"\\n\")\n",
    "\n",
    "# cmp('probs', dprobs, probs)\n",
    "# now find the gradient of probs which will the derivative from the logprob step\n",
    "print(f\"derivative of probs.log() is equivalent to log(x) which is 1/x and need to implement chain rule\\\n",
    "      \\nthat is wee need to find the derivative of probs which is dlogprobs\")\n",
    "print(\"Compare the gradients probs.grad[range(n), Yb] and dprobs[range(n), Yb]\")\n",
    "dprobs = (1.0/probs) * dlogprobs \n",
    "##take the derivative of the log(probs) and multiply it with the corresponding function's output i.e chain rule\n",
    "print('(1.0/probs) * dlogprobs  this will boost the gradient if the predicted logits / probs of the actual value is low and\\\n",
    "\\nwill remain the same if the prob is One')\n",
    "cmp('probs',dprobs,probs)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "## cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5b30694-5f35-48fa-b6e0-0ac54b42ee2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1535, -2.9885, -0.7059, -0.5712, -0.9706, -1.0810, -1.0249, -1.2433,\n",
       "        -2.2172, -0.5260, -0.5198, -2.2948, -0.5310, -1.5191, -0.9813, -1.1774,\n",
       "        -0.5821, -0.7626, -0.7233, -1.3544, -0.4752, -1.6173, -1.0304, -0.4999,\n",
       "        -0.6227, -1.6620, -0.8213, -2.5651, -1.7379, -0.8853, -0.6879, -0.6584])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.grad[range(n), Yb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28202500-bbcd-4e93-988f-da5e8985f7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1535, -2.9885, -0.7059, -0.5712, -0.9706, -1.0810, -1.0249, -1.2433,\n",
       "        -2.2172, -0.5260, -0.5198, -2.2948, -0.5310, -1.5191, -0.9813, -1.1774,\n",
       "        -0.5821, -0.7626, -0.7233, -1.3544, -0.4752, -1.6173, -1.0304, -0.4999,\n",
       "        -0.6227, -1.6620, -0.8213, -2.5651, -1.7379, -0.8853, -0.6879, -0.6584],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dprobs[range(n), Yb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b7bb739-7667-44c6-8685-707ffb14ec8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2676],\n",
       "        [-0.3402],\n",
       "        [-0.3537],\n",
       "        [-0.3531],\n",
       "        [-0.4319],\n",
       "        [-0.3514],\n",
       "        [-0.4600],\n",
       "        [-0.4145],\n",
       "        [-0.3402],\n",
       "        [-0.2326],\n",
       "        [-0.4692],\n",
       "        [-0.3242],\n",
       "        [-0.2511],\n",
       "        [-0.3506],\n",
       "        [-0.3510],\n",
       "        [-0.2535],\n",
       "        [-0.3086],\n",
       "        [-0.3263],\n",
       "        [-0.2993],\n",
       "        [-0.3345],\n",
       "        [-0.3824],\n",
       "        [-0.4308],\n",
       "        [-0.3403],\n",
       "        [-0.4233],\n",
       "        [-0.4136],\n",
       "        [-0.2119],\n",
       "        [-0.4210],\n",
       "        [-0.4640],\n",
       "        [-0.4076],\n",
       "        [-0.2860],\n",
       "        [-0.4308],\n",
       "        [-0.2877]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_sum_inv.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2283206c-e87b-45d1-8e48-5e26b00c645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27]) torch.Size([32, 1])\n",
      "the shape is not matched so it will braod cast the tensors/ logits that is the 32 columns will be broadcasted 27 times \n",
      "If we want to take the derivative of 2 fns we have to take them with respect to each other\n",
      "dcount_sum_inv shape is torch.Size([32, 1])\n",
      "counts_sum_inv  | exact: True  | approximate True  | maxdiff: 0.0\n",
      "\n",
      "we are not checking the gradienst yet because the we calculated only the first contribution of counts\n",
      "`probs = counts * counts_sum_inv` we have another contribution from the counts `counts_sum = counts.sum(1, keepdims=True)`\n",
      "dcounts_sum.shape = torch.Size([32, 1])\n",
      "counts_sum      | exact: True  | approximate True  | maxdiff: 0.0\n",
      "counts.shape torch.Size([32, 27]), counts_sum.shape torch.Size([32, 1])\n",
      "counts          | exact: True  | approximate True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "## cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "# counts_sum_inv is 1/counts_sum\n",
    "print(counts.shape, counts_sum_inv.shape)\n",
    "print(\"the shape is not matched so it will braod cast the tensors/ logits that is the 32 columns will be broadcasted 27 times \")\n",
    "\n",
    "# c = a * b\n",
    "# a[3 x 3] * b[3x1]\n",
    "# a11*b1 a12*b1 a13*b1\n",
    "# a21*b2 a22*b2 a23*b2\n",
    "# a31*b3 a32*b3 a33*b3\n",
    "\n",
    "print(\"If we want to take the derivative of 2 fns we have to take them with respect to each other\")\n",
    "# da*b/da = b    ,  da*b/db = a  and multiple the chain rule of that particular function\n",
    "#counts * dprobs will be of shape 32 * 27 but we nned 32 * 1 \n",
    "# because thats the shape of counts_sum_inv and we are doing it by adding all the gradients across the rows\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims = True)\n",
    "print(f\"dcount_sum_inv shape is {dcounts_sum_inv.shape}\")\n",
    "\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "\n",
    "# cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "#Now we have to derivate with respect to counts now\n",
    "\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "\n",
    "print(\"\\nwe are not checking the gradienst yet because the we calculated only the first contribution of counts\\n\\\n",
    "`probs = counts * counts_sum_inv` we have another contribution from the counts `counts_sum = counts.sum(1, keepdims=True)`\")\n",
    "\n",
    "# derivatives of counts_sum**-1 can be writen as d(1/x)/dx = -1/x**2\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "print(f'dcounts_sum.shape = {dcounts_sum.shape}')\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "\n",
    "#derivatives of counts.sum(1, keepdims=True)\n",
    "print(f\"counts.shape {counts.shape}, counts_sum.shape {counts_sum.shape}\")\n",
    "\n",
    "#a11 a12 a13 ----> b1 (= a11 + a12 + a13)\n",
    "#a21 a22 a23 ----> b2 (= a21 + a22 + a23)\n",
    "#a31 a32 a33 ----> b1 (= a31 + a32 + a33)\n",
    "#the derivatives of b1 sould be distributed equally across its respective inputs that is a11 a12 a13 .... applied similarly to all\n",
    "# we have to create a 32 x 27 from 32 x 1\n",
    "#we have to add the dcounts to the first branch also\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "# dcounts -> output\n",
    "# tensor([[17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747,\n",
    "#          17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747,\n",
    "#          17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747,\n",
    "#          17.9747, 17.9747, 17.9747],\n",
    "#         ...................\n",
    "# after adding the branchs of counts\n",
    "# tensor([[17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747,\n",
    "#          17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747, 17.9747,\n",
    "#          17.9747, 17.9747, 17.9747, 17.9747, 17.8570, 17.9747, 17.9747, 17.9747,\n",
    "#          17.9747, 17.9747, 17.9747],\n",
    "#         ...........\n",
    "# dcounts\n",
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb80b170-7a56-47c3-8aba-cdcabe183050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate True  | maxdiff: 0.0\n",
      "shape of dnorm_logits torch.Size([32, 27]) | shape of logits torch.Size([32, 27])| shape of logit_maxes torch.Size([32, 1])\n",
      "logit_maxes     | exact: True  | approximate True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "# local derivative of e**x is e**x\n",
    "\n",
    "dnorm_logits = counts * dcounts  #applied chain rule\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "\n",
    "# cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "#norm_logits = logits - logit_maxes\n",
    "print(f\"shape of dnorm_logits {dnorm_logits.shape} | shape of logits {logits.shape}\\\n",
    "| shape of logit_maxes {logit_maxes.shape}\")\n",
    "\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim =True)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "dlogits.shape\n",
    "\n",
    "# cmp('logits', dlogits, logits)\n",
    "# logit_maxes  = logits.max(1, keepdim=True).values\n",
    "\n",
    "dlogits += F.one_hot(logits.max(1).indices , num_classes = logits.shape[1]) * dlogit_maxes\n",
    "dlogits\n",
    "cmp('logits', dlogits, logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33d95be0-dcf3-4a09-b3b3-4889d3cf47ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26417618350>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices , num_classes = logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7a3e41e-9a47-4f59-888c-8ec8421c95d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dlogits - torch.Size([32, 27]) \n",
      "shape of h - torch.Size([32, 64]) \n",
      "shape of W2 - torch.Size([64, 27]) \n",
      "shape of b2 - torch.Size([27])\n",
      "h               | exact: True  | approximate True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# cmp('h', dh, h)\n",
    "# logits = h @ W2 + b2\n",
    "\n",
    "#we have to derivate through h @ W2 + b\n",
    "# Find the derivation in the notebook for simple problem and understand it and latter apply it for the broader picture \n",
    "# Tip to know the matrix multiplication for these parameter is \"Always look for the shape of the shapes of them\"\n",
    "# the corresponding shape of the derivative should be equal to the original shape like dh.shape == h.shape\n",
    "\n",
    "print(f\"shape of dlogits - {dlogits.shape} \\n\\\n",
    "shape of h - {h.shape} \\nshape of W2 - {W2.shape} \\nshape of b2 - {b2.shape}\")\n",
    "dh = dlogits @ W2.T\n",
    "cmp('h', dh, h)\n",
    "\n",
    "\n",
    "# cmp('W2', dW2, W2)\n",
    "dW2 = h.T @ dlogits\n",
    "cmp('W2', dW2, W2)\n",
    "\n",
    "# cmp('b2', db2, b2)\n",
    "db2 = dlogits.sum(0)\n",
    "cmp('b2', db2, b2)\n",
    "\n",
    "# cmp('hpreact', dhpreact, hpreact)\n",
    "# the derivative of tanh(x) is sech^2(x) and sech**2x = 1- tanh**2\n",
    "\n",
    "# h = torch.tanh(hpreact)\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "cmp('hpreact', dhpreact, hpreact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d99473e-49e3-4186-9f4f-57ab877a54d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapoe of dhpreacttorch.Size([32, 64]) \n",
      "shape of bngain torch.Size([1, 64]) \n",
      "shape of bnraw torch.Size([32, 64]) \n",
      "shape of bnbias torch.Size([1, 64])\n",
      "bngain          | exact: True  | approximate True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# cmp('bngain', dbngain, bngain)\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "# Lets see the shape of dhpreat, bngain, bnraw ,bnbias\n",
    "\n",
    "print(f\"shapoe of dhpreact{dhpreact.shape} \\n\\\n",
    "shape of bngain {bngain.shape} \\nshape of bnraw {bnraw.shape} \\n\\\n",
    "shape of bnbias {bnbias.shape}\")\n",
    "\n",
    "#hpreact = bngain * bnraw + bnbias are the element wise multiplication , Not Mat Mul , SO they are gonna be simple derivatives\n",
    "# Tip look for the shapes of the local derivastive and chain rule and act accordingly\n",
    "# bdnraw * dhpreact gonna be 32 x 64 , But we need it to be in the shape of bngain 1 x 64\n",
    "# if the function has 1 in its dimension use keepdims = True else Not Needed\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdims = True)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "\n",
    "#Similarly \n",
    "# cmp('bnraw', dbnraw, bnraw)\n",
    "\n",
    "dbnraw = bngain * dhpreact\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "\n",
    "# cmp('bnbias', dbnbias, bnbias)\n",
    "dbnbias = dhpreact.sum(0, keepdims= True)\n",
    "cmp('bnbias', dbnbias, bnbias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84dba147-6d9b-4dc7-92ec-faed31d4dd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dbnraw torch.Size([32, 64]) | shape of bndiff torch.Size([32, 64]) | shape of bnvar_inv torch.Size([1, 64])\n",
      "Broad Casting is happening because of the shape of bnvar_inv\n",
      "dbnvar_inv      | exact: True  | approximate True  | maxdiff: 0.0\n",
      "dbndiff         | exact: False | approximate False | maxdiff: 0.000994503148831427\n",
      "bnvar           | exact: True  | approximate True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Batch Norm Layer\n",
    "# bnmeani= 1/n*hprebn.sum(0,keepdim = True) #(hprebn.sum(0,keepdim = True)/n)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff **2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim= True) #note : Bessel's Correction (dividing by n-1 , not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff - bnvar_inv\n",
    "# hpreact = bngain * bnraw +bnbias\n",
    "\n",
    "print(f\"shape of dbnraw {dbnraw.shape} | shape of bndiff {bndiff.shape} |\\\n",
    " shape of bnvar_inv {bnvar_inv.shape}\")\n",
    "print(f\"Broad Casting is happening because of the shape of bnvar_inv\")\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdims = True)\n",
    "cmp('dbnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "\n",
    "# cmp('dbndiff', dbndiff, bndiff)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "cmp('dbndiff', dbndiff, bndiff)\n",
    "\n",
    "# cmp('bnvar', dbnvar, bnvar)\n",
    "# d (x ** -n ) / dx is -n * x ** -n-1\n",
    "dbnvar = (-0.5) * (bnvar + 1e-5) ** -1.5 * 1 * dbnvar_inv # where 1 is the ans of derivative of (bnvar + 1e-5) w.r.t bnvar\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "\n",
    "# cmp('bndiff2', dbndiff2, bndiff2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8644e7a-6b1d-4e31-b1b7-6d019a6fcc52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6047c0e-c946-4510-a71b-148595d272c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f95ca86-6c05-46f1-9b9c-287e3d5c9630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
